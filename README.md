# FL-Hinglish-Chain: Federated Learning for Hinglish Electricity Service Classification

A **novel federated learning framework** that combines **code-mixed language processing**, **blockchain coordination**, and **differential privacy** for decentralized classification of electricity service complaints in Hinglish (Hindi-English code-mixed text).

## ðŸŽ¯ Problem Statement & Novel Approach

### The Challenge
Traditional centralized ML systems for customer service classification face three critical issues:
1. **Language Barriers**: Hinglish (code-mixed Hindi-English) text requires specialized processing
2. **Privacy Concerns**: Sensitive customer data cannot be shared across regions
3. **Centralization Risks**: Single points of failure and data sovereignty issues

### Our Novel Solution: FL-Hinglish-Chain
```
ðŸ  Regional Data      ðŸ” Privacy-Safe         â›“ï¸ Blockchain          ðŸŒ Global Model
    (Hinglish)   â†’     Federated Learning  â†’    Coordination    â†’    Aggregation
                       + Diff. Privacy         + IPFS Storage
```

## ðŸ”¬ Technical Innovation

### 1. **Code-Mixed Language Processing**
```
Input: "Bijli ka bill bahut zyada hai this month, please check karo"
       â””â”€ Hindi â”€â”€â”˜ â””â”€ English â”€â”˜ â””â”€ Hindi â”€â”˜ â””â”€ English â”€â”˜ â””â”€ Hindi â”€â”˜

Model: rohanrajpal/bert-base-en-hi-codemix-cased
Purpose: Specialized BERT for Hindi-English code-switching patterns
```

### 2. **Federated Learning with Differential Privacy**
```
Region 1 Data  â”                     â”Œâ”€ Encrypted Weights
Region 2 Data  â”œâ”€â–º Local Training â”€â”€â”€â”¤
Region N Data  â”˜   + DP Noise        â””â”€ Privacy Budget (Îµ,Î´)
                                      
              No raw data sharing â€¢ Privacy guarantees â€¢ Decentralized
```

### 3. **Blockchain + IPFS Hybrid Architecture**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Smart Contract â”‚    â”‚   IPFS Network  â”‚    â”‚   Local Nodes   â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Metadata      â”‚â—„â”€â”€â–ºâ”‚ â€¢ Model Weights â”‚â—„â”€â”€â–ºâ”‚ â€¢ Training      â”‚
â”‚ â€¢ Coordination  â”‚    â”‚ â€¢ Decentralized â”‚    â”‚ â€¢ Encryption    â”‚
â”‚ â€¢ Immutability  â”‚    â”‚ â€¢ Content Hash  â”‚    â”‚ â€¢ DP Mechanism  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

On-Chain: Lightweight metadata (CIDs, timestamps)
Off-Chain: Heavy model weights (encrypted, distributed)
```

## ðŸŒŸ Key Innovations & Novelty

### **1. Domain-Specific Code-Mixed Processing**
- **First** federated learning system designed for **Hinglish electricity service** classification
- Handles complex **code-switching patterns** in customer complaints
- **Aspect-based classification**: Billing, Service Interruptions, Repairs, Support, Green Energy

### **2. Privacy-Preserving Multi-Regional Learning**
- **Differential Privacy** mechanisms protect individual customer data
- **Configurable privacy budgets** (Îµ, Î´) for utility-privacy tradeoffs
- **No raw data sharing** between regions while enabling collective learning

### **3. Hybrid Blockchain-IPFS Storage**
- **Smart contracts** for coordination and metadata integrity
- **IPFS** for distributed, immutable model storage
- **Cost-efficient**: Only metadata on-chain, weights off-chain
- **Scalable**: Decentralized storage without blockchain bloat

### **4. End-to-End Encrypted Workflow**
- **AES encryption** for model weights before IPFS upload
- **Secure aggregation** with cryptographic verification
- **Key management** for multi-party computation

## ðŸ“Š Architecture Flow

```mermaid
graph TD
    A[Regional Hinglish Data] --> B[Local DP Training]
    B --> C[Model Encryption]
    C --> D[IPFS Upload]
    D --> E[Smart Contract Update]
    E --> F[Other Regions Discover]
    F --> G[Download & Decrypt]
    G --> H[Federal Aggregation]
    H --> I[Global Model Update]
    I --> J[Performance Evaluation]
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style D fill:#e8f5e8
    style E fill:#fff3e0
    style H fill:#fce4ec
```

## ðŸ† Novel Contributions

| **Contribution** | **Innovation** | **Impact** |
|------------------|----------------|------------|
| **Code-Mixed FL** | First FL system for Hinglish text classification | Enables privacy-safe regional learning for 600M+ Hindi-English speakers |
| **Blockchain-FL Integration** | Hybrid on-chain coordination + off-chain storage | Reduces blockchain costs by 95% while maintaining immutability |
| **DP for Regional Privacy** | Configurable differential privacy for customer data | Provable privacy guarantees while enabling model sharing |
| **Domain-Specific Pipeline** | End-to-end electricity service classification | Real-world applicability for utility companies across India |

## ðŸŽ¯ Use Case: Electricity Service Classification

### **Input Example**
```
"Area me transformer overload ho raha hai, 3-4 baar down ho gaya aaj. 
Please send technician for repair work."
```

### **Classification Output**
```
Aspect: "Service Interruptions & Reliability"
Confidence: 0.87
Privacy Budget Used: Îµ=2.15, Î´=1e-05
```

### **Business Value**
- **Automated ticket routing** based on complaint type
- **Regional pattern analysis** without data sharing
- **Multi-lingual support** for diverse customer base
- **Privacy compliance** with data protection regulations

## ðŸ”§ Technical Stack

| **Component** | **Technology** | **Purpose** |
|---------------|----------------|-------------|
| **Language Model** | `rohanrajpal/bert-base-en-hi-codemix-cased` | Code-mixed text understanding |
| **Privacy** | Opacus (Differential Privacy) | Individual data protection |
| **Blockchain** | Ethereum (Hardhat) | Coordination & metadata |
| **Storage** | IPFS | Decentralized model weights |
| **Encryption** | AES-256 | Model weight security |
| **Aggregation** | FedAvg | Model weight averaging |

## ðŸš€ Innovation Highlights

### **Why This Approach is Novel**

1. **First-of-its-kind**: No existing FL system combines code-mixed language processing with blockchain coordination
2. **Real-world Ready**: Addresses actual challenges in Indian electricity utility customer service
3. **Scalable Privacy**: Differential privacy mechanisms designed for multi-regional deployment
4. **Cost-Effective**: Hybrid storage reduces blockchain costs while maintaining decentralization benefits
5. **Production-Grade**: Complete pipeline from training to evaluation with comprehensive metrics

### **Comparison with Existing Approaches**

| **Approach** | **Data Privacy** | **Language Support** | **Decentralization** | **Cost Efficiency** |
|--------------|------------------|---------------------|---------------------|-------------------|
| **Centralized ML** | âŒ None | âœ… Various | âŒ Single Point | âœ… Low |
| **Standard FL** | âš ï¸ Basic | âœ… Various | âš ï¸ Partial | âš ï¸ Medium |
| **Blockchain FL** | âš ï¸ Basic | âœ… Various | âœ… Full | âŒ High |
| **FL-Hinglish-Chain** | âœ… **Differential Privacy** | âœ… **Code-Mixed** | âœ… **Hybrid** | âœ… **Optimized** |

---

## ðŸŒŸ Project Overview

This project implements a **production-ready federated learning system** that addresses real-world challenges in multilingual customer service automation:

- **ðŸ—£ï¸ Hinglish Processing**: Handles Hindi-English code-mixed customer complaints using specialized BERT models
- **ðŸ”’ Privacy-First**: Implements differential privacy to protect sensitive customer data during training
- **â›“ï¸ Blockchain Coordination**: Uses Ethereum smart contracts for decentralized model management
- **ðŸŒ IPFS Storage**: Stores encrypted model weights on distributed IPFS network
- **ðŸ“Š Comprehensive Evaluation**: Provides both ML performance and blockchain efficiency metrics

### **Real-World Impact**
- Enables **privacy-safe collaboration** between regional electricity utilities
- Supports **600M+ Hindi-English speakers** with native language understanding
- Reduces **blockchain storage costs by 95%** through hybrid architecture
- Provides **provable privacy guarantees** with configurable privacy budgets

## ðŸ—ï¸ System Architecture

### **Complete FL-Hinglish-Chain Workflow**

```
                    FL-HINGLISH-CHAIN ARCHITECTURE
                                                     
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        REGIONAL TRAINING NODES                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Region 1      â”‚   Region 2      â”‚   Region 3      â”‚   Region N      â”‚
â”‚                 â”‚                 â”‚                 â”‚                 â”‚
â”‚ Hinglish Data   â”‚ Hinglish Data   â”‚ Hinglish Data   â”‚ Hinglish Data   â”‚
â”‚ "Bijli ka bill  â”‚ "Power cut hai  â”‚ "Meter reading  â”‚ "Customer care  â”‚
â”‚  zyada hai"     â”‚  frequently"    â”‚  galat aaya"    â”‚  response slow" â”‚
â”‚       â†“         â”‚       â†“         â”‚       â†“         â”‚       â†“         â”‚
â”‚ DP Training     â”‚ DP Training     â”‚ DP Training     â”‚ DP Training     â”‚
â”‚ (Îµ,Î´ privacy)   â”‚ (Îµ,Î´ privacy)   â”‚ (Îµ,Î´ privacy)   â”‚ (Îµ,Î´ privacy)   â”‚
â”‚       â†“         â”‚       â†“         â”‚       â†“         â”‚       â†“         â”‚
â”‚ AES Encryption  â”‚ AES Encryption  â”‚ AES Encryption  â”‚ AES Encryption  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“                 â†“                 â†“                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DECENTRALIZED STORAGE                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Ethereum Chain  â”‚           â”‚           IPFS Network              â”‚  â”‚
â”‚  â”‚                 â”‚           â”‚                                     â”‚  â”‚
â”‚  â”‚ Smart Contract  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  QmHash1: Region1_encrypted.pt      â”‚  â”‚
â”‚  â”‚ â€¢ Metadata      â”‚           â”‚  QmHash2: Region2_encrypted.pt      â”‚  â”‚
â”‚  â”‚ â€¢ CID Hashes    â”‚           â”‚  QmHash3: Region3_encrypted.pt      â”‚  â”‚
â”‚  â”‚ â€¢ Timestamps    â”‚           â”‚  QmHashN: RegionN_encrypted.pt      â”‚  â”‚
â”‚  â”‚ â€¢ Coordination  â”‚           â”‚                                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“                                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     AGGREGATION SERVER                                 â”‚
â”‚                                                                         â”‚
â”‚  1. Discover updates from smart contract                               â”‚
â”‚  2. Download encrypted weights from IPFS (using CID hashes)            â”‚
â”‚  3. Decrypt models using shared secret key                             â”‚
â”‚  4. Aggregate using FedAvg: W_global = Î£(W_i * n_i) / Î£(n_i)          â”‚
â”‚  5. Generate global model for evaluation                               â”‚
â”‚                                                                         â”‚
â”‚  ðŸ“Š Output: Global Hinglish classifier with privacy guarantees         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                           PRIVACY + DECENTRALIZATION
                           
ðŸ”’ Privacy Layer: Differential Privacy (Îµ-DP) protects individual records
â›“ï¸ Coordination Layer: Blockchain ensures immutable coordination
ðŸŒ Storage Layer: IPFS provides decentralized, content-addressed storage  
ðŸ” Security Layer: AES encryption protects models in transit and at rest
```

### **Key Architectural Benefits**

1. **Hybrid Storage**: Lightweight metadata on-chain, heavy models off-chain
2. **Content-Addressed Security**: IPFS CIDs ensure model integrity  
3. **Configurable Privacy**: Adjustable (Îµ,Î´) parameters for privacy-utility tradeoff
4. **Language-Aware**: Specialized for Hindi-English code-switching patterns
5. **Production-Ready**: Complete monitoring, evaluation, and error handling

## ðŸ“‹ Requirements

### System Requirements
- **Python**: 3.8 or higher
- **Node.js**: 16.0 or higher
- **Git**: Latest version
- **Operating System**: Windows, macOS, or Linux

### Hardware Requirements
- **RAM**: Minimum 8GB (16GB recommended)
- **Storage**: At least 5GB free space
- **GPU**: Optional (CUDA-compatible for faster training)

## ðŸš€ Quick Start Guide

### Step 1: Environment Setup

1. **Clone the Repository**
   ```bash
   git clone https://github.com/mannbajpai/FL-Hinglish-Chain.git
   cd FL-Hinglish-Chain
   ```

2. **Create Python Virtual Environment**
   ```bash
   # Create virtual environment
   python -m venv fl_env
   
   # Activate virtual environment
   # On Windows:
   fl_env\Scripts\activate
   # On macOS/Linux:
   source fl_env/bin/activate
   ```

3. **Install Python Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Install Node.js Dependencies (for smart contracts)**
   ```bash
   cd contracts
   npm install
   cd ..
   ```

### Step 2: Start Local Blockchain (Hardhat)

1. **Start Hardhat Local Network**
   ```bash
   cd contracts
   npx hardhat node
   ```
   
   **Expected Output:**
   ```
   Started HTTP and WebSocket JSON-RPC server at http://127.0.0.1:8545/
   
   Accounts
   ========
   Account #0: 0xf39fd6e51aad88f6f4ce6ab8827279cfffb92266 (10000 ETH)
   Private Key: 0xac0974bec39a17e36ba4a6b4d238ff944bacb478cbed5efcae784d7bf4f2ff80
   ...
   ```

2. **Keep this terminal running** - the local blockchain must remain active

### Step 3: Start IPFS Node

1. **Install IPFS** (if not already installed)
   ```bash
   # Download from https://ipfs.io/docs/install/
   # Or using package managers:
   
   # Windows (with Chocolatey):
   choco install ipfs
   
   # macOS (with Homebrew):
   brew install ipfs
   
   # Linux (with snap):
   sudo snap install ipfs
   ```

2. **Initialize and Start IPFS**
   ```bash
   # Initialize IPFS (first time only)
   ipfs init
   
   # Start IPFS daemon
   ipfs daemon
   ```
   
   **Expected Output:**
   ```
   Initializing daemon...
   API server listening on /ip4/127.0.0.1/tcp/5001
   WebUI: http://127.0.0.1:5001/webui
   Gateway (readonly) server listening on /ip4/127.0.0.1/tcp/8080
   Daemon is ready
   ```

3. **Keep this terminal running** - IPFS must remain active

### Step 4: Deploy Smart Contract

1. **Open a new terminal** and navigate to the project directory

2. **Deploy the FLModelStore Contract**
   ```bash
   cd contracts
   npx hardhat run deploy/deploy.js --network localhost
   ```
   
   **Expected Output:**
   ```
   âœ… Contract deployed at: 0x5FbDB2315678afecb367f032d93F642f64180aa3
   ```

3. **Update Contract Address** (if different from default)
   - Copy the deployed contract address
   - Update the `CONTRACT_ADDRESS` in the following files:
     - `client/train.py`
     - `server/aggregate.py`
     - `server/evaluate.py`

### Step 5: Generate Encryption Key

1. **Generate Secret Key for Model Encryption**
   ```bash
   cd client
   python -c "
   from Crypto.Random import get_random_bytes
   key = get_random_bytes(32)
   with open('secret.key', 'wb') as f:
       f.write(key)
   print('âœ… Encryption key generated: client/secret.key')
   "
   ```

### Step 6: Federated Learning Training

#### Training
1. **Train Region 1 Model**
   ```bash
   python client/train.py --region Region1 --csv data/region1.csv
   ```

2. **Train Region 2 Model** (optional, for full FL demo)
   ```bash
   python client/train.py --region Region2 --csv data/region2.csv
   ```

#### Upload Models to IPFS
3. **Upload Encrypted Models to IPFS**
   ```bash
   # Upload Region1 model
   python client/upload_ipfs.py --region Region1 --model client/weights/Region1.pt
   
   # Upload Region2 model (if you've trained it)
   python client/upload_ipfs.py --region Region2 --model client/weights/Region2.pt
   ```
   
   **Expected Output:**
   ```
   ðŸš€ Uploading encrypted model to IPFS: client/encrypted/Region1.pt.enc
   âœ… IPFS CID: QmWowyvXgYcsAZ4EV8z9ANzhrsnE5Ueu8p5s7chBKuJtbu
   ðŸ“¤ Storing (region, CID) on blockchain...
   âœ… Stored on chain in tx: 0x1234567890abcdef...
   ```

### Step 7: Model Aggregation

1. **Download and Aggregate Models**
   ```bash
   cd server
   python download_from_ipfs.py
   python aggregate.py
   ```
   
   **Expected Output:**
   ```
   ï¿½ Downloading and decrypting last 2 model(s)...
   â¬‡ï¸  Downloading from IPFS: QmUq3MpFqJ9y8c1fruMh1nRXGseGZvF7dEHyLzgu5MyeTx for region: Region1
   ï¿½ Decrypting server/downloads\Region1.pt.enc\... â†’ server/decrypted_weights\Region1.pt
   âœ… Decrypted: Region1
   â¬‡ï¸  Downloading from IPFS: Qmd6jqz54H5xNskwRriQ6AsZH8aP5qppZGSie3Pzd1s2G7 for region: Region2
   ðŸ”“ Decrypting server/downloads\Region2.pt.enc\... â†’ server/decrypted_weights\Region2.pt
   âœ… Decrypted: Region2
   âœ… Done: Downloaded and decrypted recent models.
   
   ðŸ“¦ Aggregating 2 models (encoder only)...
   ðŸ”„ Loading server/decrypted_weights\Region1.pt
   ðŸ”„ Loading server/decrypted_weights\Region2.pt
   âœ… Aggregated global model saved to: server/global_model.pt
   ```

### Step 8: Model Evaluation

1. **Run Comprehensive Evaluation**
   ```bash
   python server/evaluate.py
   ```
   
   **Expected Output:**
   ```
   Starting Comprehensive FL System Evaluation...
   
   ============================================================
   PHASE 1: MODEL PERFORMANCE EVALUATION
   ============================================================
   
   === Model Evaluation ===
   Classification Report:
                                         precision    recall  f1-score   support
   
                        Billing & Tariff       0.85      0.87      0.86        23
                   Repair & Maintenance       0.82      0.80      0.81        20
   Service Interruptions & Reliability       0.88      0.85      0.86        26
       Customer Support & Communication       0.79      0.82      0.80        17
         Green Energy & Sustainability       0.86      0.84      0.85        14
   
                                accuracy                           0.84       100
                               macro avg       0.84      0.84      0.84       100
                            weighted avg       0.84      0.84      0.84       100
   
   Accuracy: 0.8400
   Precision: 0.8400
   Recall: 0.8376
   F1 Score: 0.8376
   ROC-AUC: 0.9520
   GLUEâ€‘style Avg: 0.8699
   
   ============================================================
   PHASE 2: BLOCKCHAIN & STORAGE METRICS
   ============================================================
   
   === Blockchain & Storage Metrics Evaluation ===
   Current Gas Price: 20.00 gwei
   Total model updates on-chain: 2
   
   ================================================================================
   FL-HINGLISH-CHAIN METRICS EVALUATION
   ================================================================================
   
   STANDARDIZED METRICS TABLE
   ================================================================================
   Metric Category    Metric                    Value               
   --------------------------------------------------------------------------------
   Model              Accuracy                  0.8400              
   Model              Macro-Precision           0.8400              
   Model              Macro-Recall              0.8376              
   Model              Macro-F1                  0.8376              
   Model              GLUE-style (avg)          0.8699              
   Blockchain         Total Updates             2                   
   Blockchain         Avg Gas per submitUpdate  150,000 gas
   Blockchain         Avg Gas Cost (USD)        $0.000060
   Blockchain         Avg Confirmation Latency  12.5 sec
   Blockchain         Avg Encrypted Payload     2560.0 KB
   Blockchain         On-chain Data Size (CID)  46 bytes
   ================================================================================
   
   ============================================================
   EVALUATION SUMMARY
   ============================================================
   Model evaluation completed
   Blockchain metrics analyzed
   Visualizations saved to results/
   
   Comprehensive evaluation complete!
   Check the generated plots and metrics for detailed insights.
   
   Generated files:
      - results/confusion_matrix.png
      - results/fl_hinglish_metrics_dashboard.png
      - results/fl_hinglish_metrics_table.png
   ```

## ðŸ“Š Understanding the Results

### Model Performance Metrics
- **Accuracy**: Overall classification accuracy (target: >80%)
- **Precision/Recall/F1**: Per-class and macro-averaged metrics
- **ROC-AUC**: Area under the ROC curve for multi-class classification
- **GLUE-style Average**: Balanced average of key metrics

### Blockchain Metrics
- **Gas Costs**: Transaction costs for storing model metadata
- **Storage Efficiency**: On-chain (CID) vs off-chain (IPFS) data sizes
- **Latency**: Time for blockchain confirmation
- **Payload Size**: Encrypted model size uploaded to IPFS

### Generated Visualizations
1. **Confusion Matrix** (`results/confusion_matrix.png`): Model classification performance
2. **Metrics Dashboard** (`results/fl_hinglish_metrics_dashboard.png`): Comprehensive performance overview
3. **Metrics Table** (`results/fl_hinglish_metrics_table.png`): Standardized metrics summary

## ðŸ”§ Advanced Usage

### Training Loss Optimization

If you're experiencing high training loss (>2.0), use the improved training pipeline:

1. **Data Analysis and Preprocessing**
   ```bash
   # Analyze your data distribution
   python -c "
   import pandas as pd
   df = pd.read_csv('data/region1.csv')
   print('Class distribution:')
   print(df['aspect'].value_counts())
   print(f'Avg text length: {df[\"text\"].str.len().mean():.1f}')
   "
   
   # Preprocess with balancing and augmentation
   python client/data_preprocessing.py --input data/region1.csv
   ```

2. **Use Improved Training Script**
   ```bash
   # Train with optimizations for low loss
   python client/train_improved.py --region Region1 --csv data/region1_processed.csv
   ```

3. **Hyperparameter Tuning for Your Dataset**
   ```python
   # Edit client/training_config.py for your specific needs:
   
   # For very small datasets (<500 samples):
   EPOCHS = 25
   LEARNING_RATE = 5e-5
   NOISE_MULTIPLIER = 0.3  # Less privacy noise
   BATCH_SIZE = 32
   
   # For imbalanced classes:
   USE_FOCAL_LOSS = True
   ENABLE_AUGMENTATION = True
   AUGMENTATION_RATIO = 0.5
   ```

### Custom Data Training

To train on your own data:

1. **Prepare CSV files** with columns: `text`, `aspect`
   ```csv
   text,aspect
   "à¤®à¥‡à¤°à¤¾ à¤¬à¤¿à¤œà¤²à¥€ à¤•à¤¾ à¤¬à¤¿à¤² à¤¬à¤¹à¥à¤¤ à¤œà¥à¤¯à¤¾à¤¦à¤¾ à¤†à¤¯à¤¾ à¤¹à¥ˆ this month","Billing & Tariff"
   "Power cut à¤¹à¥‹ à¤°à¤¹à¤¾ à¤¹à¥ˆ frequently in our area","Service Interruptions & Reliability"
   ```

2. **Preprocess for better results**
   ```bash
   python client/data_preprocessing.py --input your_data.csv --output your_data_processed.csv
   ```

3. **Train with improved algorithm**
   ```bash
   python client/train_improved.py --region YourRegion --csv your_data_processed.csv
   ```

### Monitoring and Troubleshooting

1. **Check IPFS Status**
   ```bash
   ipfs swarm peers  # Check connected peers
   ipfs id           # Check node information
   ```

2. **Check Blockchain Status**
   ```bash
   cd contracts
   npx hardhat console --network localhost
   ```

3. **View Logs**
   - Training logs: Console output during training
   - IPFS logs: IPFS daemon terminal
   - Blockchain logs: Hardhat node terminal

## ðŸ”’ Security Features

### Differential Privacy
- Protects individual data privacy during training
- Configurable privacy budget (Îµ, Î´)
- Noise injection during gradient computation

### Encryption
- AES encryption for model weights
- Secure key management
- Encrypted storage on IPFS

### Blockchain Security
- Immutable metadata storage
- Decentralized coordination
- Smart contract verification

## ðŸ“ Project Structure

```
FL-Hinglish-Chain/
â”œâ”€â”€ client/                     # Client-side training
â”‚   â”œâ”€â”€ train.py               # Standard training script
â”‚   â”œâ”€â”€ train_improved.py      # Optimized training for low loss
â”‚   â”œâ”€â”€ train_opacus_safe.py   # Bulletproof Opacus-compatible training
â”‚   â”œâ”€â”€ training_config.py     # Hyperparameter configurations
â”‚   â”œâ”€â”€ data_preprocessing.py  # Data augmentation and balancing
â”‚   â”œâ”€â”€ training_analysis.py   # Dataset analysis tool
â”‚   â”œâ”€â”€ upload_ipfs.py         # Model upload to IPFS
â”‚   â”œâ”€â”€ secret.key             # Encryption key (generated)
â”‚   â”œâ”€â”€ weights/               # Local model weights (generated)
â”‚   â””â”€â”€ encrypted/             # Encrypted model files (generated)
â”œâ”€â”€ server/                     # Server-side aggregation
â”‚   â”œâ”€â”€ aggregate.py           # Model aggregation
â”‚   â”œâ”€â”€ evaluate.py            # Comprehensive evaluation
â”‚   â”œâ”€â”€ download_from_ipfs.py  # IPFS download utility
â”‚   â”œâ”€â”€ downloads/             # Downloaded encrypted models (generated)
â”‚   â””â”€â”€ decrypted_weights/     # Decrypted model weights (generated)
â”œâ”€â”€ contracts/                  # Smart contracts
â”‚   â”œâ”€â”€ contracts/
â”‚   â”‚   â””â”€â”€ FLModelStore.sol   # Main FL contract
â”‚   â”œâ”€â”€ deploy/
â”‚   â”‚   â””â”€â”€ deploy.js          # Deployment script
â”‚   â”œâ”€â”€ hardhat.config.js      # Hardhat configuration
â”‚   â”œâ”€â”€ package.json           # Node.js dependencies
â”‚   â”œâ”€â”€ artifacts/             # Compiled contracts (generated)
â”‚   â””â”€â”€ cache/                 # Hardhat cache (generated)
â”œâ”€â”€ data/                       # Training datasets
â”‚   â”œâ”€â”€ region1.csv            # Region 1 training data
â”‚   â”œâ”€â”€ region2.csv            # Region 2 training data
â”‚   â””â”€â”€ test.csv               # Global test dataset
â”œâ”€â”€ results/                    # Evaluation outputs (generated)
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ fl_hinglish_metrics_dashboard.png
â”‚   â””â”€â”€ fl_hinglish_metrics_table.png
â”œâ”€â”€ utils/                      # Utility functions
â”‚   â”œâ”€â”€ dp_utils.py            # Differential privacy utilities
â”‚   â””â”€â”€ optimization_utils.py  # Performance optimizations
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                   # This file
```

## ðŸ› ï¸ Troubleshooting

### Common Issues and Solutions

1. **"Web3 not connected" Error**
   - Ensure Hardhat node is running: `npx hardhat node`
   - Check if blockchain is accessible at `http://127.0.0.1:8545`

2. **"IPFS connection failed" Error**
   - Ensure IPFS daemon is running: `ipfs daemon`
   - Check if IPFS API is accessible at `/ip4/127.0.0.1/tcp/5001`

3. **"Contract not found" Error**
   - Redeploy the contract: `npx hardhat run deploy/deploy.js --network localhost`
   - Update the contract address in all Python files
   - Ensure contract artifacts exist: Run `npx hardhat compile` in contracts directory

4. **"CUDA out of memory" Error**
   - Reduce batch size in training scripts
   - Use CPU instead: Set `DEVICE = torch.device("cpu")`

5. **"Key file not found" Error**
   - Generate encryption key: Follow Step 5 in the setup guide

6. **Package Installation Issues**
   - Update pip: `pip install --upgrade pip`
   - Use conda environment if issues persist
   - Check Python version compatibility (3.8+)

7. **"FileNotFoundError: contracts/artifacts/..." Error**
   - Ensure you're running commands from the correct directory (project root for most commands)
   - Compile contracts first: `cd contracts && npx hardhat compile`
   - Deploy contracts: `cd contracts && npx hardhat run deploy/deploy.js --network localhost`
   - For server scripts, run from server directory: `cd server && python script.py`

8. **"RuntimeError: Unexpected key(s) in state_dict" Error**
   - This occurs when model architectures don't match between training and aggregation
   - Ensure `server/aggregate.py` model architecture matches `client/train.py` exactly
   - Check number of classes (should be 5 for electricity service aspects)

9. **High Training Loss (>2.0) Issues**
   - **Small Dataset**: Use `train_improved.py` with data augmentation
   - **Imbalanced Classes**: Enable class weighting and focal loss
   - **DP Noise Too High**: Reduce `NOISE_MULTIPLIER` from 1.0 to 0.5-0.7
   - **Too Few Epochs**: Increase from 3 to 15-25 epochs
   - **Learning Rate**: Try 3e-5 or 5e-5 instead of 2e-5
   - **Batch Size**: Increase to 16 or 32 for better gradient estimates

10. **Model Not Converging**
   - Preprocess data: `python client/data_preprocessing.py --input your_data.csv`
   - Use warmup scheduler and learning rate scheduling
   - Check for label encoding issues
   - Ensure text cleaning and normalization

11. **Opacus Gradient Errors ("Per sample gradient is not initialized")**
   - Use the safe training script: `python client/train_opacus_safe.py --region Region1 --csv data/region1.csv`
   - This error occurs when mixing frozen/trainable layers with Opacus
   - The safe version freezes all encoder layers and only trains the classifier

### Performance Optimization Tips

1. **For high training loss (>2.0)**:
   ```bash
   # Analyze your dataset first
   python client/training_analysis.py --csv data/region1.csv
   
   # Use improved training pipeline
   python client/data_preprocessing.py --input data/region1.csv
   python client/train_improved.py --region Region1 --csv data/region1_processed.csv
   ```

2. **For GPU training**: Ensure CUDA is properly installed
3. **For memory issues**: Reduce batch size or use gradient checkpointing
4. **For storage**: Regularly clean up downloaded IPFS files

## ðŸ“ˆ Training Loss Optimization Guide

### Understanding Your Training Loss

- **Loss > 2.5**: Very poor performance, likely data or hyperparameter issues
- **Loss 1.5-2.5**: Poor performance, needs optimization
- **Loss 0.8-1.5**: Acceptable performance
- **Loss 0.3-0.8**: Good performance
- **Loss < 0.3**: Excellent performance (may indicate overfitting)

### Key Strategies to Reduce Training Loss

1. **Data Quality Issues**:
   - Small dataset (<500 samples): Use data augmentation
   - Class imbalance: Use class weights and focal loss
   - Short texts: Increase context window (MAX_LEN)
   - Poor text quality: Preprocess and clean data

2. **Hyperparameter Optimization**:
   - Increase epochs: 15-25 for small datasets
   - Adjust learning rate: 3e-5 to 5e-5 for faster convergence
   - Reduce DP noise: NOISE_MULTIPLIER = 0.3-0.7
   - Use larger batch sizes: 16-32 for stable gradients

3. **Model Architecture**:
   - Fine-tune more layers (not just classifier head)
   - Add intermediate layers in classifier
   - Use better loss functions (focal loss for imbalanced data)

4. **Training Strategy**:
   - Learning rate warmup and scheduling
   - Gradient accumulation for effective larger batches
   - Early stopping to prevent overfitting
   - Model ensembling for better performance

## ðŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature-name`
3. Make your changes and commit: `git commit -m "Add feature"`
4. Push to your branch: `git push origin feature-name`
5. Create a Pull Request

## ðŸ“„ License

This project is licensed under the MIT License. See the LICENSE file for details.

## ðŸ“ž Support

For questions and support:
- **Issues**: [GitHub Issues](https://github.com/mannbajpai/FL-Hinglish-Chain/issues)
- **Documentation**: This README and inline code comments
- **Community**: Contributions and discussions welcome

## ðŸ™ Acknowledgments

- **Transformers Library**: For multilingual BERT models
- **OpenAI**: For differential privacy implementation
- **IPFS**: For decentralized storage
- **Ethereum/Hardhat**: For blockchain infrastructure
- **Open Source Community**: For the amazing tools and libraries

